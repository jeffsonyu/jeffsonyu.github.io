<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhenjun Yu</title>
  
  <meta name="author" content="Zhenjun Yu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<!-- 	<link rel="icon" href="icon.png">
 -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhenjun Yu</name>
              </p>
              <p>
                My name is Zhenjun Yu. I'm a graduate student majoring in <b>Information Engineering</b> 
                in Shanghai Jiao Tong University (SJTU), advised by Prof. <a href="https://www.mvig.org">Cewu Lu</a> and Dr. <a href="https://wenqiangx.github.io/">Wenqiang Xu</a>. I am expected to graduate in March. 2026.
                My educational experiences include:
                <ul>
                  <li><b>Bachelor of Arts (B.Art) @ French, minor in Information Engineering</b>, <br />
                    Shanghai Jiao Tong University, Shanghai, China, Sep. 2019 - Jun. 2023;</li>
                  <li><b>Master of Engineering (M.Eng) @ Information Engineering</b>, <br />
                    Shanghai Jiao Tong University, Shanghai, China, Sep. 2023 - Mar. 2026 (expected).</li>
                </ul>
                My research interest lies in <b>Robotics</b>, <b>Tactile Sensing</b>, <b>3D Reconstruction</b>, and <b>Reinforcement Learning</b>. I'm currently looking for job opportunities in <b>Embodied AI</b>, <b>Imitation Learning</b>, and <b>Tactile sensing for manipulation</b>.
	            </p>
              <p>
                My hobbies include basketball, debates and Model United Nations. I was a member of the basketball team and debate team of our institute.
              </p>
		  <!-- <p>     Please email me at haoyux.me@gmail.com, as my CMU email has expired.</a>. -->



	    <!-- <p align=center style="margin-top:-8px;" ><a href="https://twitter.com/Haoyu_Xiong_" class="twitter-follow-button" data-show-count="false">Follow @Haoyu_Xiong_</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p> -->

              <p>
              <p style="text-align:center">
                <a href="mailto:jeffson-yu.sjtu.edu.cn">Email</a> &nbsp/&nbsp
                <a href="CV_full.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com.hk/citations?user=SAgSdaAAAAAJ&hl=zh-CN">Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/jeffsonyu">Github</a> &nbsp
		      

		      
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="yzj.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="yzj.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
          
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
		    
        <p>
		 [Aug. 2025] 1 paper accepted by CoRL 2025!   
		<br>
	     [Jun. 2025] 1 paper accepted by ICCV 2025!   
		<br>
         [Dec. 2024] 1 paper accepted by RA-L!   
         	<br>
         [Sept. 2024] 1 paper accepted by Nature Communications!     
	       <br>
         [July. 2024] 1 paper accepted by RA-L!     
	       <br>
         [Feb. 2024] 1 paper accepted by CVPR 2024!
	       <br>
         [Jan. 2024] 1 paper accepted by RA-L!
	       <br>
         [Aug. 2023] 1 paper accepted by CoRL 2023!
	       <br>
         [Apr. 2023] 1 paper accepted by RSS 2023!
         <br>
         [Feb. 2023] 1 paper accepted by CVPR 2023!
	       </p>
            </td>
          
<!DOCTYPE HTML>
<html lang="en">

<head>
    <title>Research</title>
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" type="images/png" href="images/favicon.png">
    <link rel="canonical" href="https://yourwebsite.com/">
    <link href='https://fonts.googleapis.com/css?family=Nunito' rel='stylesheet'>

    <style>
        img {
            vertical-align: middle;
        }

        .research-row {
            display: flex;
            align-items: center;
            margin-bottom: 30px;
        }

        .image-container {
            width: 25%;
            text-align: center;
        }

        .text-container {
            width: 75%;
            padding-left: 20px;
        }

        h3 {
            margin: 0;
            padding-bottom: 10px;
        }
    </style>

    <script>
        function npil_start() {
            document.getElementById('npil_image').style.opacity = "1";
        }

        function npil_stop() {
            document.getElementById('npil_image').style.opacity = "0";
        }
        npil_stop()
    </script>
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tr style="padding:0px">
            <td style="padding:0px">
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" border="0">
                    <tr style="padding:0px">
		            <td style="padding:20px;width:100%;vertical-align:middle">
				    
				<heading>Research</heading>
                        </td>
                    </tr>
                </table>
                * indicates equal contribution.
                <br><br>
		    
                <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
                    <div class="image-container">
                        <img src='tnt.gif' width="150" height="130">
                    </div>
                    <div class="text-container">
                        <a href="https://proceedings.mlr.press/v229/yu23c/yu23c.pdf">
                            <h4>Precise Robotic Needle-Threading with Tactile Perception and Reinforcement Learning</h4>
                        </a>
                        <strong>Zhenjun Yu</strong>*, Wenqiang Xu*, Siqiong Yao, Jieji Ren, Tutian Tang, Yutong Li, Guoying Gu, Cewu Lu
                        <br>
                        Conference on Robot Learning (CoRL) 2023
			<br><br>
                        <a href="https://proceedings.mlr.press/v229/yu23c/yu23c.pdf">PDF</a> / <a href="https://sites.google.com/view/tac-needlethreading">website</a>
                    </div>
                </div>

                
                <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
                  <div class="image-container">
                      <img src='vtaco.png' width="90" height="150">
                  </div>
                  <div class="text-container">
                      <a href="https://arxiv.org/pdf/2303.14498">
                          <h4>Visual-Tactile Sensing for In-Hand Object Reconstruction</h4>
                      </a>
                      Wenqiang Xu*, <strong>Zhenjun Yu</strong>*, Han Xue, Ruolin Ye, Siqiong Yao, Cewu Lu.
                      <br>
                      IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023  
      <br><br>
                        <a href="https://arxiv.org/pdf/2303.14498">PDF</a> / <a href="https://sites.google.com/view/vtaco/">website</a>
                    </div>
                </div>



                <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
                  <div class="image-container">
                      <img src='vitamd.jpg' width="170" height="80">
                  </div>
                  <div class="text-container">
                      <a href="https://arxiv.org/pdf/2411.09572?">
                          <h4>Dynamic Reconstruction of Hand-Object Interaction with Distributed Force-aware Contact Representation</h4>
                      </a>
                      <strong>Zhenjun Yu</strong>*, Wenqiang Xu*, Pengfei Xie, Yutong Li, Cewu Lu
                      <br>
                      IEEE/CVF International Conference on Computer Vision (ICCV) 2025
      <br><br>
                        <a href="https://arxiv.org/pdf/2411.09572?">PDF</a>
                    </div>
                </div>



                <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
                  <div class="image-container">
                      <img src='agentworld.gif' width="160" height="120">
                  </div>
                  <div class="text-container">
                      <a href="https://jeffsonyu.github.io/">
                          <h4>AgentWorld:An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation</h4>
                      </a>
                      Yizheng Zhang*, <strong>Zhenjun Yu</strong>*, Jiaxin Lai, Cewu Lu, Lei Han
                      <br>
                      Conference on Robot Learning (CoRL) 2025
      <br><br>
                        <a href="https://arxiv.org/abs/2508.07770">PDF</a> / <a href="https://yizhengzhang1.github.io/agent_world/">website</a>
                    </div>
                </div>
				


				<div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
                  <div class="image-container">
                      <img src='raorft.jpg' width="180" height="100">
                  </div>
                  <div class="text-container">
                      <a href="https://jeffsonyu.github.io/">
                          <h4>Offline reinforced finetuning for chunk-based VLA via real-world RL policy distillation with vision-guided copilot</h4>
                      </a>
                      Yihao Wu*, <strong>Zhenjun Yu*</strong>, Shun Yin, Zhihao Wang, Xueqian Wang
                      <br>
                      IEEE International Conference on Robotics & Automation (ICRA) 2026, in Review
      <br><br>
                      <a href="https://jeffsonyu.github.io/">PDF</a>
                  </div>
              </div>

				

                <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
                  <div class="image-container">
                      <img src='fbi.gif' width="180" height="100">
                  </div>
                  <div class="text-container">
                      <a href="https://jeffsonyu.github.io/">
                          <h4>FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy</h4>
                      </a>
                      Yijin Chen*, Wenqiang Xu*, <strong>Zhenjun Yu</strong>, Tutian Tang, Yutong Li, Siqiong Yao, Cewu Lu 
                      <br>
                      IEEE International Conference on Robotics & Automation (ICRA) 2026, in Review
      <br><br>
                      <a href="https://jeffsonyu.github.io/">PDF</a> / <a href="https://sites.google.com/view/dex-fbi">website</a>
                  </div>
              </div>



              <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
                <div class="image-container">
                    <img src='dextog.png' width="170" height="90">
                </div>
                <div class="text-container">
                    <a href="https://ieeexplore.ieee.org/document/10803020?denied=">
                        <h4>DexTOG: Learning Task-Oriented Dexterous Grasp with Language Condition</h4>
                    </a>
                    Jieyi Zhang, Wenqiang Xu, <strong>Zhenjun Yu</strong>, Pengfei Xie, Tutian Tang, Cewu Lu
                    <br>
                    IEEE Robotics and Automation Letters (RA-L) 2024
      <br><br>
                    <a href="https://ieeexplore.ieee.org/document/10803020?denied=">PDF</a> / <a href="https://sites.google.com/view/dextog">website</a>
                </div>
            </div>


            <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
              <div class="image-container">
                  <img src='tacipc.png' width="170" height="90">
              </div>
              <div class="text-container">
                  <a href="https://arxiv.org/pdf/2311.05843">
                      <h4>TacIPC: Intersection-and Inversion-free FEM-based Elastomer Simulation For Optical Tactile Sensors</h4>
                  </a>
                  Wenxin Du, Wenqiang Xu, Jieji Ren, <strong>Zhenjun Yu</strong>, Cewu Lu
                  <br>
                  IEEE Robotics and Automation Letters (RA-L) 2024
      <br><br>
                  <a href="https://arxiv.org/pdf/2311.05843">PDF</a> / <a href="https://sites.google.com/view/tac-ipc">website</a>
              </div>
          </div>


          <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
            <div class="image-container">
                <img src='vitam.png' width="150" height="120">
            </div>
            <div class="text-container">
                <a href="https://www.nature.com/articles/s41467-024-53654-y.pdf#:~:text=Here%2C%20we%20report%20a%20visual-tactile%20recording%20and%20tracking,framework%20to%20estimate%20dynamic%20hand-object%20states%20during%20manipulation.">
                    <h4>Capturing forceful interaction with deformable objects using a deep learning-powered stretchable tactile array</h4>
                </a>
                Chunpeng Jiang*, Wenqiang Xu*, Yutong Li, <strong>Zhenjun Yu</strong> et al.
                <br>
                Nature Communications 2024
      <br><br>
                <a href="https://www.nature.com/articles/s41467-024-53654-y.pdf#:~:text=Here%2C%20we%20report%20a%20visual-tactile%20recording%20and%20tracking,framework%20to%20estimate%20dynamic%20hand-object%20states%20during%20manipulation.">PDF</a> / <a href="https://github.com/jeffsonyu/ViTaM">website</a>
            </div>
        </div>


        <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
          <div class="image-container">
              <img src='dipgrasp.jpg' width="120" height="150">
          </div>
          <div class="text-container">
              <a href="https://arxiv.org/pdf/2408.04738">
                  <h4>DiPGrasp: Parallel Local Searching for Efficient Differentiable Grasp Planning</h4>
              </a>
              Wenqiang Xu*, Jieyi Zhang*, Tutian Tang, <strong>Zhenjun Yu</strong>, Yutong Li, Cewu Lu
              <br>
              IEEE Robotics and Automation Letters (RA-L) 2024
      <br><br>
              <a href="https://arxiv.org/pdf/2408.04738">PDF</a> / <a href="https://dipgrasp.robotflow.ai/">website</a>
          </div>
      </div>



      <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
        <div class="image-container">
            <img src='rfu.gif' width="150" height="150">
        </div>
        <div class="text-container">
            <a href="https://arxiv.org/pdf/2202.00199">
                <h4>Rfuniverse: A Multiphysics Simulation Platform for Embodied AI</h4>
            </a>
            Haoyuan Fu*, Wenqiang Xu*, Ruolin Ye*, Han Xue, <strong>Zhenjun Yu</strong>, Tutian Tang, Yutong Li, Wenxin Du, Jieyi Zhang, Cewu Lu
            <br>
            Robotics: Science and Systems (RSS) 2023
      <br><br>
            <a href="https://arxiv.org/pdf/2202.00199">PDF</a> / <a href="https://sites.google.com/view/rfuniverse/">website</a>
        </div>
      </div>



      <div class="research-row" onmouseout="npil_stop()" onmouseover="npil_start()">
        <div class="image-container">
            <img src='msmano.png' width="170" height="90">
        </div>
        <div class="text-container">
            <a href="https://arxiv.org/pdf/2404.10227">
                <h4>MS-MANO: Enabling Hand Pose Tracking with Biomechanical Constraints</h4>
            </a>
            Pengfei Xie*, Wenqiang Xu*, Tutian Tang, <strong>Zhenjun Yu</strong>, Cewu Lu
            <br>
            IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023  
      <br><br>
            <a href="https://arxiv.org/pdf/2404.10227">PDF</a> / <a href="https://ms-mano.robotflow.ai/">website</a>
        </div>
      </div>

			    

			                        </div>
                </div>
            </td>
        </tr>
    </table>
</body>

		              
	

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tr style="padding:0px">
            <td style="padding:0px">
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" border="0">
                    <tr style="padding:0px">
		            <td style="padding:20px;width:100%;vertical-align:middle">
	
        		      <heading>Professional Service</heading>
              <p>
               Reviewer: ICCV 25', CoRL 25'. 
              </p>
            </td>
          </tr>

		 


	
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">template</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
